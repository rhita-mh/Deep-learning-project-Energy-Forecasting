# ğŸ¯ EntraÃ®ner avec le Code Exact du Notebook

## âœ… Solution : Utiliser le Code Exact du Notebook

J'ai crÃ©Ã© un nouveau script `train_models_from_notebook.py` qui utilise **EXACTEMENT** le mÃªme code que votre notebook, cellule par cellule.

## ğŸ“‹ DiffÃ©rences ClÃ©s

### Ancien script (`train_models.py`) :
- ModÃ¨les simplifiÃ©s
- Epochs: 50
- Patience: 10
- Pas de LearningRateScheduler
- Pas de ModelCheckpoint

### Nouveau script (`train_models_from_notebook.py`) :
- âœ… **ModÃ¨les "Improved"** (exactement comme le notebook)
- âœ… **Epochs: 100** (comme le notebook)
- âœ… **Patience: 15** (comme le notebook)
- âœ… **LearningRateScheduler** avec warmup et cosine decay
- âœ… **ModelCheckpoint** pour sauvegarder les meilleurs poids
- âœ… **MÃªme architecture** exacte
- âœ… **MÃªmes hyperparamÃ¨tres** exacts

## ğŸš€ Comment Utiliser

### Ã‰TAPE 1 : Activer l'environnement
```bash
conda activate tf_clean
```

### Ã‰TAPE 2 : Aller dans le dossier
```bash
cd C:\Users\asus\Desktop\cur
```

### Ã‰TAPE 3 : ExÃ©cuter le nouveau script
```bash
python train_models_from_notebook.py
```

## â±ï¸ Temps d'ExÃ©cution

- **Decision Tree** : ~1 minute
- **MLP Improved** : ~10-15 minutes (100 epochs avec early stopping)
- **CNN Improved** : ~10-15 minutes
- **LSTM Improved (Univariate)** : ~15-20 minutes
- **LSTM Improved (Multivariate)** : ~20-25 minutes

**Total estimÃ©** : **1-2 heures** (mais avec early stopping, Ã§a peut Ãªtre plus rapide)

## âœ… Ce qui va se passer

1. âœ… Chargement des donnÃ©es (identique au notebook)
2. âœ… PrÃ©paration des donnÃ©es (identique au notebook Cell 47)
3. âœ… EntraÃ®nement Decision Tree (identique au notebook Cell 44)
4. âœ… EntraÃ®nement MLP Improved (identique au notebook Cell 53)
5. âœ… EntraÃ®nement CNN Improved (identique au notebook Cell 55)
6. âœ… EntraÃ®nement LSTM Improved Univariate (identique au notebook Cell 57)
7. âœ… EntraÃ®nement LSTM Improved Multivariate (identique au notebook Cell 59)
8. âœ… Calcul des mÃ©triques (identique au notebook Cell 48)
9. âœ… Sauvegarde des modÃ¨les et mÃ©triques

## ğŸ“Š RÃ©sultats Attendus

Les mÃ©triques devraient Ãªtre **identiques** Ã  celles du notebook car :
- âœ… MÃªme code exact
- âœ… MÃªmes hyperparamÃ¨tres
- âœ… MÃªmes callbacks
- âœ… MÃªme architecture
- âœ… MÃªme split train/test

## ğŸ” VÃ©rification

Ã€ la fin, vous verrez :
```
Decision Tree Performance:
============================================================
RMSE: 229.734 MW
MAE:  157.272 MW
RÂ²:   0.9480
============================================================

MLP (Improved) Performance:
============================================================
RMSE: [valeur du notebook]
MAE:  [valeur du notebook]
RÂ²:   [valeur du notebook]
============================================================
...
```

## âš ï¸ Notes Importantes

1. **Les modÃ¨les seront rÃ©-entraÃ®nÃ©s** : Les anciens modÃ¨les seront remplacÃ©s
2. **Cela prendra du temps** : Environ 1-2 heures avec early stopping
3. **Les mÃ©triques seront calculÃ©es automatiquement** : Pas besoin de script sÃ©parÃ©
4. **Les modÃ¨les seront sauvegardÃ©s** : Dans le dossier `models/`

## ğŸ¯ AprÃ¨s l'EntraÃ®nement

1. **VÃ©rifier les mÃ©triques** : Elles devraient correspondre au notebook
2. **RedÃ©marrer l'application Streamlit** :
   ```bash
   streamlit run app.py
   ```
3. **VÃ©rifier dans l'application** : Les mÃ©triques devraient Ãªtre correctes

## â“ ProblÃ¨mes Possibles

### Si les mÃ©triques sont toujours diffÃ©rentes :
- VÃ©rifier que les donnÃ©es sont identiques (mÃªme nombre de lignes aprÃ¨s drop_duplicates)
- VÃ©rifier que les versions de TensorFlow/Keras sont identiques
- VÃ©rifier les random seeds (42 pour numpy et TensorFlow)

### Si l'entraÃ®nement est trop long :
- C'est normal, les modÃ¨les "Improved" prennent plus de temps
- Early stopping arrÃªtera automatiquement si nÃ©cessaire

---

**C'est tout ! ExÃ©cutez `python train_models_from_notebook.py` et vous obtiendrez les mÃªmes rÃ©sultats que le notebook ! ğŸš€**

